{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_Linear(\n",
      "  (gen): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator_Linear(\n",
      "  (dis): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import get_Generator, get_Discriminator\n",
    "\n",
    "generator = get_Generator(from_old_model=False, model_path=None, device='cpu', G_type=\"L\")\n",
    "discriminator = get_Discriminator(from_old_model=False, model_path=None, device='cpu', D_type=\"L\")\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_Conv(\n",
      "  (expand): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=256, out_features=484, bias=True)\n",
      "    (5): BatchNorm1d(484, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): LeakyReLU(negative_slope=True)\n",
      "  )\n",
      "  (gen): Sequential(\n",
      "    (0): ConvTranspose2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=True)\n",
      "    (3): ConvTranspose2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=True)\n",
      "    (6): ConvTranspose2d(8, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=True)\n",
      "    (9): ConvTranspose2d(4, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (10): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=True)\n",
      "    (12): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator_Conv(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=36864, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = get_Generator(from_old_model=False, model_path=None, device='cpu', G_type=\"C\")\n",
    "discriminator = get_Discriminator(from_old_model=False, model_path=None, device='cpu', D_type=\"C\")\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'data'\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    # 将像素值从 [0, 255] 转换到 [0, 1]\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # 将像素值从 [0, 1] 转换到 [-1, 1], 将输入的图像按照通道进行标准化\n",
    "    # MINIST 数据集是灰度图像，只有一个通道，所以 mean 和 std 都是一个数\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "])\n",
    "\n",
    "target_transform = transforms.Lambda(lambda y: torch.tensor(y, dtype=torch.float32))\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# len = 60000, each element is a tuple of (image, label), image's shape (1, 28, 28)\n",
    "minist_train = torchvision.datasets.MNIST(\n",
    "    root=output_path,\n",
    "    train=True,\n",
    "    transform=img_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# len = 10000, each element is a tuple of (image, label), image's shape (1, 28, 28)\n",
    "minist_test = torchvision.datasets.MNIST(\n",
    "    root=output_path,\n",
    "    train=False,\n",
    "    transform=img_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data_loader = data.DataLoader(\n",
    "    dataset=minist_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_data_loader = data.DataLoader(\n",
    "    dataset=minist_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "for X, y in train_data_loader:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from model import *\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from_old_model = False\n",
    "\n",
    "img_seed_dim = 256\n",
    "\n",
    "G_model_path = 'model/G_model.pth'\n",
    "D_model_path = 'model/D_model.pth'\n",
    "\n",
    "G_type = 'Linear'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('device:', device)\n",
    "\n",
    "img_output_path = f'output_images/{G_type}'\n",
    "\n",
    "if not os.path.exists(img_output_path):\n",
    "    os.makedirs(img_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model = get_Generator(\n",
    "    from_old_model=from_old_model, model_path=G_model_path, device=device, G_type=G_type\n",
    "    )\n",
    "\n",
    "D_model = get_Discriminator(\n",
    "    from_old_model=from_old_model, model_path=D_model_path, device=device\n",
    "    )\n",
    "\n",
    "G_optimizer = AdamW(G_model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "D_optimizer = AdamW(D_model.parameters(), lr=1e-4, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "[epoch: 0 batch: 1/938] D_loss: 0.591601, G_loss: 3.395355\n",
      "Epoch 1/5 D_loss: 0.591601, G_loss: 3.395355\n",
      "Time: 0.701381\n",
      "Epoch 2/5\n",
      "[epoch: 1 batch: 1/938] D_loss: 0.272522, G_loss: 5.340329\n",
      "Epoch 2/5 D_loss: 0.272522, G_loss: 5.340329\n",
      "Time: 1.073398\n",
      "Epoch 3/5\n",
      "[epoch: 2 batch: 1/938] D_loss: 0.266933, G_loss: 6.585814\n",
      "Epoch 3/5 D_loss: 0.266933, G_loss: 6.585814\n",
      "Time: 1.438436\n",
      "Epoch 4/5\n",
      "[epoch: 3 batch: 1/938] D_loss: 0.234293, G_loss: 7.945290\n",
      "Epoch 4/5 D_loss: 0.234293, G_loss: 7.945290\n",
      "Time: 1.802925\n",
      "Epoch 5/5\n",
      "[epoch: 4 batch: 1/938] D_loss: 0.287280, G_loss: 9.170646\n",
      "Epoch 5/5 D_loss: 0.287280, G_loss: 9.170646\n",
      "Time: 2.160757\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    batch_num = len(train_data_loader)\n",
    "    D_loss_sum = torch.Tensor([0.0]).to(device)\n",
    "    G_loss_sum = torch.Tensor([0.0]).to(device)\n",
    "    count = torch.Tensor([0]).to(device)\n",
    "\n",
    "    for index, (images, _) in enumerate(train_data_loader):\n",
    "        count += 1\n",
    "\n",
    "        real_images = images.to(device)\n",
    "        real_labels = (1 - torch.rand(batch_size)/10).to(device)\n",
    "\n",
    "        fake_images = G_model(torch.randn(batch_size, img_seed_dim).to(device))\n",
    "        fake_labels = Variable(torch.zeros(batch_size)).to(device)\n",
    "\n",
    "        D_optimizer.zero_grad()\n",
    "        real_output = D_model(real_images)\n",
    "        D_loss_real = criterion(real_output, real_labels)\n",
    "        fake_output = D_model(fake_images)\n",
    "        D_loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        D_loss_sum += D_loss.item()\n",
    "\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        fake_images = G_model(torch.randn(batch_size, img_seed_dim).to(device))\n",
    "        fake_output = D_model(fake_images)\n",
    "\n",
    "        G_loss = criterion(fake_output, real_labels)\n",
    "        G_loss_sum += G_loss.item()\n",
    "\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        print(f'[epoch: {epoch} batch: {index + 1}/{batch_num}] D_loss: {D_loss.item():.6f}, G_loss: {G_loss.item():.6f}')\n",
    "        break\n",
    "    \n",
    "    torch.save(G_model.state_dict(), G_model_path)\n",
    "    torch.save(D_model.state_dict(), D_model_path)\n",
    "\n",
    "    fake_images = G_model(torch.randn(64, img_seed_dim).to(device)).cpu().detach()\n",
    "\n",
    "    fake_images = (fake_images + 1) * 0.5\n",
    "    fake_images = fake_images.clamp(0, 1)\n",
    "\n",
    "    fake_images = fake_images.view(-1, 1, 28, 28)\n",
    "    save_image(fake_images, f'{img_output_path}/epoch_{epoch}.png')\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs} D_loss: {(D_loss_sum / count).item():.6f}, G_loss: {(G_loss_sum / count).item():.6f}')\n",
    "    current_time = time.time()\n",
    "    print(f'Time: {(current_time - train_start):.6f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G_L_D_L_G_model.pth', 'G_L_D_L_D_model.pth', 'output_images/G_L_D_L']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
