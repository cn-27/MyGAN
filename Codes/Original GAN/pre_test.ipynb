{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'data'\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    # 将像素值从 [0, 255] 转换到 [0, 1]\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # 将像素值从 [0, 1] 转换到 [-1, 1], 将输入的图像按照通道进行标准化\n",
    "    # MINIST 数据集是灰度图像，只有一个通道，所以 mean 和 std 都是一个数\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "])\n",
    "\n",
    "target_transform = transforms.Lambda(lambda y: torch.tensor(y, dtype=torch.float32))\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# len = 60000, each element is a tuple of (image, label), image's shape (1, 28, 28)\n",
    "minist_train = torchvision.datasets.MNIST(\n",
    "    root=output_path,\n",
    "    train=True,\n",
    "    transform=img_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# len = 10000, each element is a tuple of (image, label), image's shape (1, 28, 28)\n",
    "minist_test = torchvision.datasets.MNIST(\n",
    "    root=output_path,\n",
    "    train=False,\n",
    "    transform=img_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data_loader = data.DataLoader(\n",
    "    dataset=minist_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_data_loader = data.DataLoader(\n",
    "    dataset=minist_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "for X, y in train_data_loader:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from model import *\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from_old_model = False\n",
    "\n",
    "img_seed_dim = 256\n",
    "\n",
    "G_model_path = 'model/G_model.pth'\n",
    "D_model_path = 'model/D_model.pth'\n",
    "\n",
    "G_type = 'Linear'\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "print('device:', device)\n",
    "\n",
    "img_output_path = f'output_images/{G_type}'\n",
    "\n",
    "if not os.path.exists(img_output_path):\n",
    "    os.makedirs(img_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model = get_Generator(\n",
    "    from_old_model=from_old_model, model_path=G_model_path, device=device, G_type=G_type\n",
    "    )\n",
    "\n",
    "D_model = get_Discriminator(\n",
    "    from_old_model=from_old_model, model_path=D_model_path, device=device\n",
    "    )\n",
    "\n",
    "G_optimizer = AdamW(G_model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "D_optimizer = AdamW(D_model.parameters(), lr=1e-4, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "[epoch: 0 batch: 1/938] D_loss: 0.591601, G_loss: 3.395355\n",
      "Epoch 1/5 D_loss: 0.591601, G_loss: 3.395355\n",
      "Time: 0.701381\n",
      "Epoch 2/5\n",
      "[epoch: 1 batch: 1/938] D_loss: 0.272522, G_loss: 5.340329\n",
      "Epoch 2/5 D_loss: 0.272522, G_loss: 5.340329\n",
      "Time: 1.073398\n",
      "Epoch 3/5\n",
      "[epoch: 2 batch: 1/938] D_loss: 0.266933, G_loss: 6.585814\n",
      "Epoch 3/5 D_loss: 0.266933, G_loss: 6.585814\n",
      "Time: 1.438436\n",
      "Epoch 4/5\n",
      "[epoch: 3 batch: 1/938] D_loss: 0.234293, G_loss: 7.945290\n",
      "Epoch 4/5 D_loss: 0.234293, G_loss: 7.945290\n",
      "Time: 1.802925\n",
      "Epoch 5/5\n",
      "[epoch: 4 batch: 1/938] D_loss: 0.287280, G_loss: 9.170646\n",
      "Epoch 5/5 D_loss: 0.287280, G_loss: 9.170646\n",
      "Time: 2.160757\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    batch_num = len(train_data_loader)\n",
    "    D_loss_sum = torch.Tensor([0.0]).to(device)\n",
    "    G_loss_sum = torch.Tensor([0.0]).to(device)\n",
    "    count = torch.Tensor([0]).to(device)\n",
    "\n",
    "    for index, (images, _) in enumerate(train_data_loader):\n",
    "        count += 1\n",
    "\n",
    "        real_images = images.to(device)\n",
    "        real_labels = (1 - torch.rand(batch_size)/10).to(device)\n",
    "\n",
    "        fake_images = G_model(torch.randn(batch_size, img_seed_dim).to(device))\n",
    "        fake_labels = Variable(torch.zeros(batch_size)).to(device)\n",
    "\n",
    "        D_optimizer.zero_grad()\n",
    "        real_output = D_model(real_images)\n",
    "        D_loss_real = criterion(real_output, real_labels)\n",
    "        fake_output = D_model(fake_images)\n",
    "        D_loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        D_loss_sum += D_loss.item()\n",
    "\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        fake_images = G_model(torch.randn(batch_size, img_seed_dim).to(device))\n",
    "        fake_output = D_model(fake_images)\n",
    "\n",
    "        G_loss = criterion(fake_output, real_labels)\n",
    "        G_loss_sum += G_loss.item()\n",
    "\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        print(f'[epoch: {epoch} batch: {index + 1}/{batch_num}] D_loss: {D_loss.item():.6f}, G_loss: {G_loss.item():.6f}')\n",
    "        break\n",
    "    \n",
    "    torch.save(G_model.state_dict(), G_model_path)\n",
    "    torch.save(D_model.state_dict(), D_model_path)\n",
    "\n",
    "    fake_images = G_model(torch.randn(64, img_seed_dim).to(device)).cpu().detach()\n",
    "\n",
    "    fake_images = (fake_images + 1) * 0.5\n",
    "    fake_images = fake_images.clamp(0, 1)\n",
    "\n",
    "    fake_images = fake_images.view(-1, 1, 28, 28)\n",
    "    save_image(fake_images, f'{img_output_path}/epoch_{epoch}.png')\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs} D_loss: {(D_loss_sum / count).item():.6f}, G_loss: {(G_loss_sum / count).item():.6f}')\n",
    "    current_time = time.time()\n",
    "    print(f'Time: {(current_time - train_start):.6f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5248, 0.5074, 0.4984, 0.5115, 0.5192, 0.4901, 0.5084, 0.5015, 0.4984,\n",
       "        0.5089, 0.5063, 0.5022, 0.5060, 0.5078, 0.4988, 0.5136, 0.4849, 0.5090,\n",
       "        0.5118, 0.5168, 0.4973, 0.4943, 0.4978, 0.5110, 0.4982, 0.5111, 0.5067,\n",
       "        0.4848, 0.5006, 0.5208, 0.4896, 0.4981, 0.4998, 0.5179, 0.5138, 0.5145,\n",
       "        0.5198, 0.4982, 0.5120, 0.5019, 0.5092, 0.5161, 0.4977, 0.5145, 0.5019,\n",
       "        0.5388, 0.4922, 0.4962, 0.5170, 0.5112, 0.5151, 0.4792, 0.4982, 0.5084,\n",
       "        0.5005, 0.5248, 0.5121, 0.5243, 0.5010, 0.5292, 0.5040, 0.5259, 0.4850,\n",
       "        0.4992], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
